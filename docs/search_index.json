[["index.html", "Apuntes de estadística matemática Capítulo 1 Prerequisites", " Apuntes de estadística matemática Hector Henry Jurado Soto 2024-03-28 Capítulo 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. "],["intro.html", "Capítulo 2 Introduction", " Capítulo 2 Introduction You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 2. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter 4. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figura 2.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 2.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 2.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Tabla 2.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2024) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). Mi referencia (K. Blitzstein and Hwang 2019). References "],["literature.html", "Capítulo 3 Literature", " Capítulo 3 Literature Here is a review of existing methods. "],["methods.html", "Capítulo 4 Methods 4.1 math example", " Capítulo 4 Methods We describe our methods in this chapter. Math can be added in body using usual syntax like this 4.1 math example \\(p\\) is unknown but expected to be around 1/3. Standard error will be approximated \\[ SE = \\sqrt(\\frac{p(1-p)}{n}) \\approx \\sqrt{\\frac{1/3 (1 - 1/3)} {300}} = 0.027 \\] You can also use math in footnotes like this1. We will approximate standard error to 0.0272 where we mention \\(p = \\frac{a}{b}\\)↩︎ \\(p\\) is unknown but expected to be around 1/3. Standard error will be approximated \\[ SE = \\sqrt(\\frac{p(1-p)}{n}) \\approx \\sqrt{\\frac{1/3 (1 - 1/3)} {300}} = 0.027 \\]↩︎ "],["applications.html", "Capítulo 5 Applications 5.1 Example one 5.2 Example two", " Capítulo 5 Applications Some significant applications are demonstrated in this chapter. 5.1 Example one 5.2 Example two "],["final-words.html", "Capítulo 6 Final Words", " Capítulo 6 Final Words We have finished a nice book. "],["espacios-muestrales-y-conteo.html", "Capítulo 7 Espacios muestrales y conteo 7.1 Espacios muestrales 7.2 Definicion ingenua de probabilidad (Naive definition of probability) 7.3 Probabilidad y conteo 7.4 Ajuste por sobreconteo (Adjusting or overcounting)", " Capítulo 7 Espacios muestrales y conteo 7.1 Espacios muestrales Definición 7.1 (Espacio muestral y evento) El espacio muestral \\(S\\) de un experimento es el conjunto de todos los posibles resultados de un experimento. Un evento \\(A\\) es un subconjunto del espacio muestral \\(S\\) y se dice que \\(A\\) ocurrió si el resultado actual pertenece a \\(A\\) (K. Blitzstein and Hwang 2019) Figura 7.1: Un espacio muestral es como un mundo de canicas con dos eventos \\(A\\) y \\(B\\) El espacio muestral de un experimento puede ser finito o infinito contable o infinito incontable, cuando el espacio muestral es finito puede visualizarse como un mundo de canicas, como muestra la figura. Cada canica representa un resultado, y un evento es un conjunto de canicas. Realizar un experimento es equivalente a escoger una canica en forma aleatoria. Por ejemplo, sea \\(S\\) el espacio muestral de un experimento y sean \\(A\\) y \\(B\\) eventos. Entonces, la unión \\(A \\cup B\\) es el evento que ocurre si y solo si al menos uno de \\(A\\) y \\(B\\) ocurre, la intersección \\(A \\cap B\\) es el evento que ocurre si y solo si ambos \\(A\\) y \\(B\\) ocurren, y el complemento \\(A^c\\) es el evento que ocurre si y solo si \\(A\\) no ocurre. También tenemos las leyes de De Morgan: \\[\\begin{equation} (A \\cup B)^c = A^c \\cap B^c \\textrm{ and } (A \\cap B)^c = A^c \\cup B^c \\tag{7.1} \\end{equation}\\] puesto que decir que no es el caso que al menos uno de \\(A\\) y \\(B\\) ocurra es lo mismo que decir que \\(A^c\\) no ocurre y \\(B^c\\) no ocurre, y decir que no es el caso que ambos ocurran es lo mismo que decir que al menos uno no ocurre. Resultados análogos se mantienen para uniones e intersecciones de más de dos eventos. En el ejemplo mostrado en la Figura, \\(A\\) es un conjunto de \\(n\\) canicas, \\(B\\) es un conjunto de \\(m\\) canicas, \\(A \\cup B\\) consiste en los \\(n + m\\) canicas en \\(A\\) o \\(B\\) (incluyendo el canicas que está en ambos), \\(A \\cap B\\) consiste en las canicas que está en ambos \\(A\\) y \\(B\\), y \\(A^c\\) consiste en las \\(n\\) canicas que no están en \\(A\\). En el ejemplo de la figura, \\(A\\) es un conjunto de 5 canicas,\\(B\\) es un conjunto de 4 canicas, \\(A \\cup B\\) es un conjunto de 8 canicas, incluyendo la que esta en los dos conjuntos, \\(A \\cap B\\) es un conjunto de 1 canica y \\(A^c\\) consiste en cuatro canicas que no están en \\(A\\) Ejemplo 7.1 (Espacio muestral y evento) Una moneda es lanzada 10 veces , se escribirá heads como \\(H\\) y tails como \\(T\\), un posible resultado es \\(HHHTHHTTHT\\), el espacio muestral es el conjunto de todas las posibles cadenas de longitud 10 de \\(H&#39;s\\) y \\(T&#39;s\\). Se puede codificar \\(H\\) como \\(1\\) y \\(T\\) como \\(0\\), asi que un resultado es una secuencia \\((s_1,s_2,s_3, ..., s_{10}))\\) con \\(s_j \\in \\{0, 1\\}\\), y el espacio muestral es el conjunto de todas esas secuencias. Veamos ahora algunos eventos: Sea \\(A_1\\) el evento en que la primer lanzamiento es Head \\[ A_1 = {(1,s_2, ...,s_{10}) }: s_j \\in\\ \\{0,1\\} , 2 \\leq j \\leq 10\\] Este es un subconjunto del espacio muestral, o sea un evento, decir que \\(A_1\\) ocurre es lo mismo que decir que el primer lanzamiento es Head. Similarmente se dice que \\(A_j\\) es el evento en que el \\(j_{esimo}\\) lanzamiento es Head, donde j =2,3,…,10. Sea \\(B\\) el evento en el que al menos un lanzamiento fue head \\[ B = \\bigcup_{j=1}^{10} A_j \\] Sea \\(C\\) el evento en el que todos los lanzamientos fueron heads \\[ C = \\bigcap_{j=1}^{10} A_j \\] Sea \\(D\\) el evento en que hubo al menos dos Heads consecutivos \\[ C = \\bigcup_{j=1}^{9} ( A_j \\cap A_{j+1} ) \\] 7.2 Definicion ingenua de probabilidad (Naive definition of probability) Históricamente, la definición de probabilidad de un evento fue contar el número de maneras en que evento puede suceder y dividir por el número total de resultados posibles del experimento. Definición 7.2 (Definición ingenua de probabilidad) Sea \\(A\\) un evento para un experimento con un espacio muestral finito \\(S\\) . la probabilidad ingenua de \\(A\\) es \\[\\begin{equation} P_{naive} (A) = \\frac{|A|}{|S|} = \\frac { numero\\, de\\, resultados\\, favorables\\, de\\, A}{total\\, numero\\, de\\, resultados\\, en\\, S} \\tag{7.2} \\end{equation}\\] en donde \\(|A|\\) es el tamaño (cardinalidad ) del conjunto \\(A\\) La definición ingenua es muy restrictiva en que esto requiere que \\(S\\) sea finito, con igual masa para cada uno de las canicas por ejemplo. A a menudo es mal aplicado por personas que asumen resultados igualmente probables sin justificación y presentan argumentos en el sentido de ” o sucederá o no sucederá y no sabemos cual, así que es 50-50”. Por ejemplo, si no sabemos si hay vida en saturno ¿deberíamos concluir que es 50-50? ¿Que pasa con la vida inteligente en saturno, que parece que debería ser estrictamente menos probable que exista alguna forma de vida en saturno ? Sin embargo hay varios tipos importantes de problemas en los que la definición ingenua es aplicable, como cuando hay simetría en el problema, que hace que los resultados sean igualmente probables.(K. Blitzstein and Hwang 2019) 7.3 Probabilidad y conteo Calcular la probabilidad ingenua de un evento \\(A\\) implica contar el numero de canicas en \\(A\\) y el numero de canicas en el espacio muestral \\(S\\). A menudo estos conjuntos con extremadamente grandes, por lo que podría ser tedioso o inviable contar las posibilidades uno a uno. Para abordar este desafío existen algunas técnicas de conteo. Teorema 7.1 (Regla de la multiplicación) Consideremos un experimento compuesto consistiendo en dos sub-experimentos, experimento \\(A\\) y experimento \\(B\\). supongamos que el experimento \\(A\\) tiene \\(a\\) posibles resultados y para cada uno de esos resultados el experimento \\(B\\) tiene \\(b\\) posibles resultados, entonces el experimento compuesto tiene \\(ab\\) posibles resultados Imaginemos un diagrama como muestra la figura, consta de Ejemplo 7.2 (conos de helado) Supongamos que estamos comprando un helado en cono, se puede escoger entre un cake(pastel) o un waffle(oblea) y cada uno de ellos puede tener chocolate , vainilla o fresa como su sabor Figura 7.2: Diagrama de árbol para un cono de helado Por la regla de la multiplicación existen \\(2.3=3.2=6\\) posibilidades. Pero debemos tener en cuenta algunas cosas como: No importa si se elige primero el tipo de cono ( “quiero un cono de waffles con helado de chocolate” ) o el sabor (“Quiero un cono de chocolate en un cono de waffles”), de cualquier forma hay posibilidades. No importa si los mismos sabores están disponibles en un cono de pastel que en un cono de oblea, Lo que importa es que hay exactamente tres opciones de sabor para cada opción de cono, si por algún motivo estuviese prohibido tener un sabor de chocolate en un cono de oblea por ejemplo ( y sin sustituto, ) , hay posibilidades pero la regla de multiplicación no aplicaría. Podemos usar la regla de multiplicación para llegar a fórmulas de muestreo con y sin reemplazo. Muchos experimentos en probabilidad y estadística pueden interpretarse en un de estos dos contextos, por lo que es atractivo que ambas fórmulas seigan directamente el mismo principio básico de conteo. Teorema 7.2 (Muestreo con reemplazo) Consideremos \\(n\\) objetos y tomamos \\(k\\) de ellos, una a la vez con reemplazo( es decir elegir un determinado objeto no impide que se elija nuevamente). entonces hay \\(n^k\\) posibles resultados Por ejemplo, imaginemos que un frasco con \\(n\\) canicas, etiquetadas del 1 a \\(n\\), tomamos muestras de las bolas, una a la vez con reemplazo, lo que significa que cada vez que se elige una bola, se devuelve al frasco. Cada bola muestreada es un sub-experimento con \\(n\\) posibles resultados, y hay \\(k\\) sub-experimentos, entonces mediante la regla de multiplicación , hay \\(n^k\\) formas de obtener una muestra de tamaño \\(k\\) Figura 7.3: Muestreo con reemplazo cuando n=5 y k = 2 Teorema 7.3 (Muestreo sin reemplazo) Consideremos \\(n\\) objetos y tomamos \\(k\\) de ellos, una a la vez sin reemplazo( es decir elegir un determinado objeto y se impide que se elija nuevamente). entonces hay \\(n(n-1) ... (n-k+1)\\) posibles resultados , para \\(k \\leq n\\) y (0 posibilidades para \\(k&gt;n\\)) Figura 7.4: Muestreo sin reemplazo cuando n=5 y k = 2 El resultado es consecuencia directa de la regla de multiplicación: cada canica muestreada es otra vez un sub-experimento, y el número de posibles resultados decrece en uno (1) cada vez. Notemos que para muestrear \\(k\\) de \\(n\\) objetos sin reemplazo, necesitamos \\(k \\leq n\\), mientras que en el muestreo con reemplazo los objetos son inagotables. Ejemplo 7.3 (Permutaciones y factoriales) Una permutación de \\(1,2,...,n\\) es una disposicion de ellos en algun orden, ej. \\(3,5,1,2,4\\) es una permutación de \\(1,2,3,4,5\\) por el teorema 7.3 con \\(k=n\\) tendríamos que hay \\(n!\\) permutaciones de \\(1,2,...,n\\). Por ejemplo hay \\(n!\\) maneras en las cuales \\(n\\) personas pueden alinearse en una fila para comprar un helado Los teoremas 7.2 y 7.3 se refieren a conteo, pero cuando la definición de probabilidad ingenua aplica, podemos usarlos para calcular probabilidades Ejemplo 7.4 (Problema del nacimiento) Existen \\(k\\) personas en un cuarto, asumimos que los cumpleaños de cada persona son igualmente probables para cualquiera de los \\(365\\) días del año (se excluye febrero 29), y que los cumpleaños son independientes ( no hay gemelos en el cuarto), cual es la probabilidad que dos o mas personas en el grupo tengan la misma fecha de cumpleaños. Solución La definición de probabilidad ingenua dice que solo necesitamos contar el numero de formas para asignar cumpleaños a \\(k\\) personas de tal forma que hay dos o mas personas comparten la misma fecha de cumpleaños. Este problema de conteo es un poco complejo, puesto que por ejemplo Emma y Steve comparten la fecha de cumpleaños, o Steve y Naomi o los tres juntos, o tres de ellos pueden compartir la fecha de cumpleaños, mientras otros dos en el grupo comparten fecha de nacimiento diferentes, o un monton de otras posibilidades. En vez de eso, contemos el complemento: el numero de maneras para asignar cumpleaños a \\(k\\) personas de tal forma que no haya dos personas que compartan un cumpleaños. Esto equivale a un muestreo de los 365 dias del año sin reemplazo, es decir para la primera persona, hay \\(365\\) opciones para elegir el día del año de su cumpleaños, para la segunda persona, quedan 364 opciones, ya que no puede compartir el mismo día de cumpleaños con la primera persona. De manera similar, para la tercera persona quedan 363 opciones, puesto que no puede compartir el mismo día de cumpleaños con las dos primeras personas, de igual forma para la \\(k-esima\\) persona hay \\(365-k+1\\) opciones, por lo tanto el numero total de formas de asignar cumpleaños es por el teorema 7.3 de \\(365.364.363...(365-k+1)\\) para \\(k \\leq 365\\) Sea \\(A\\) el evento de obtener formas en que todas \\(k\\) personas cumplen años en días diferentes, por tanto \\(|A|=365.364.363...(365-k+1)\\) El total de formas posibles de asignar cumpleaños en el cuarto es \\(|S|=365^k\\), a las \\(k\\) personas, ya que cada persona puede tener su cumpleaños en cualquiera de los 365 días del año, de acuerdo al teorema 7.2 por tanto : \\[P(A)=\\frac{|A|}{|B|} =\\frac{365.364.363...(365-k+1)}{365^k} \\] \\[P(A)=\\frac{|A|}{|B|} =\\frac{365.364.363...(365-k+1)}{365^k} \\] Por tanto la probabilidad de que al menos una fecha de cumpleaños coincida es; \\[1 - P(A) = 1- \\frac{365.364.363...(365-k+1)}{365^k} \\] La figura realizada con python dibuja la probabilidad de que al menos una fecha de cumpleaños concuerda como una funcion de \\(k\\). con \\(k=23\\) la probabilidad de coincidencia excede \\(0.5\\), para \\(k=57\\) la probabilidad es cercana al %99% Figura 7.5: Probabilidad de que en un cuarto de \\(k\\) personas al menos dos nacen en el mismo día Ver codigo fuente en python - probabilidades en funcion de $k Etiquetar objetos Extraer una muestra de una población es un concepto muy fundamental en estadística, es importante pensar en los objetos o personas de la población como nombrados o etiquetados. Por ejemplo si hay \\(n\\) bolas en un frasco, podemos imaginar que ellas tienen etiquetas desde \\(1\\) a \\(n\\), incluso si las bolas se ven iguales al ojo humano. A cada persona en el problema del cumpleaños , podemos darle un numero de identificación en lugar de pensar en las personas como partículas indistinguibles. 7.4 Ajuste por sobreconteo (Adjusting or overcounting) En muchos problemas de conteo, no es fácil contar directamente cada posibilidad una vez y solo una vez. Sin embargo si podemos contar cada posibilidad exactamente \\(c\\) veces para algun \\(c\\), entonce podemos ajustar dividiendo por \\(c\\). Por ejemplo, si hemos contado exactamente dos veces cada posibilidad, podemos dividir por \\(2\\) para obtener el conteo correcto. Ejemplo 7.5 (Comites y equipos) Consideremos un grupo de cuatro personas cuantas maneras hay de escoger un comité de dos personas cuantas maneras hay de dividir las personas en dos equipos de dos. Solución Una manera de contar las posibilidades es listar las personas etiquetándolas como 1,2,3,4 entonces las posibilidades son {1,2},{1,3},{1,4},{2,3},{2,4},{3,4} otra aproximación es usar la regla de multiplicación con un ajuste por sobreconteo. Por la regla de multiplicación hay \\(4\\) formas de escoger la primera persona y \\(3\\) maneras de escoger la segunda persona en el comité, pero esto cuenta cada posibilidad dos veces , como escoger las personas \\(1\\) y \\(2\\) es lo mismo que escoger las personas \\(2\\) y \\(1\\) tenemos un sobreconteo por un factor de \\(2\\) , el numero de posibilidades es \\((4.3)/2=6\\) hay \\(3\\) maneras de formar los equipos posibilidad 1 {1,2},{3,4} posibilidad 2 {1,3},{2,4} posibilidad 3 {1,4},{2,3} Listar todas las posibilidades puede ser tedioso o inviable con mas personas Una segunda forma es fijar el compañero 1 del equipo de la persona 1 y luego determinar el otro equipo. Otra forma es que sabemos en la solución (a) que hay \\(6\\) formas de escoger un equipo. escoger {1,2} para formar un equipo es lo mismo que escoger {3,4} para formar los dos equipos, así que la respuesta es \\(6/2=3\\) Existe un coeficiente llamado coeficiente binomial que cuenta el numero de subconjuntos de cierto tamaño para un conjunto , tal que el numero de formas de escoger un comité de tamaño \\(k\\) de un conjunto de \\(n\\) personas. Los conjuntos y los subconjuntos son por definición no ordenados es decir {3,1,4}= {4,1,3}, así que lo que contamos es el numero de maneras de escoger \\(k\\) objetos de \\(n\\) sin reemplazo y sin distinguir entre los diferentes ordenes Definición 7.3 (Coeficiente binomial) Para cualquier enteros no negativos \\(k\\) y \\(n\\), el coeficiente binomial \\(\\binom{n}{k}\\), se lee combinatoria de \\(n\\) en \\(k\\) o n choose k es el número de subconjuntos de tamaño \\(k\\) para un conjunto de tamaño \\(n\\) sin importar el orden Teorema 7.4 (Formula del coeficiente binomial) para \\(n\\) y \\(k\\) enteros no negativos y \\(k \\leq n\\) \\[\\begin{equation} \\binom{n}{k} = \\frac{ n(n-1) ...(n-k+1)}{k!} = \\frac{n!}{(n-k)!k!} \\tag{7.3} \\end{equation}\\] si \\(k&gt;n\\) \\[\\begin{equation} \\binom{n}{k} = 0 \\tag{7.4} \\end{equation}\\] Prueba: sea \\(A\\) un conjunto con \\(|A|=n\\) cualquier subconjunto de \\(A\\) tiene un maximo de \\(n\\) elementos así que \\(\\binom{n}{k} = 0\\) El teorema 7.3 dice que hay \\(n(n-1) ...(n-k+1)\\) maneras de realizar una escogencia ordenada de \\(k\\) elementos sin reemplazo Esto cuenta en exceso cada subconjunto de interés por un factor de \\(k!\\) (ya que no nos importa cómo se ordenan estos elementos), por lo que podemos obtener el conteo correcto dividiendo por \\(k!\\) Ejemplo 7.6 (Club de oficiales) en un club de \\(n\\) personas , hay \\(n(n-1)(n-2)\\)formas de escoger un presidente, vicepresidente y tesorera, por tanto hay \\(\\binom{n}{3} = \\frac{ n(n-1)(n-2)}{3!}\\) formas de escoger 3 oficiales sin títulos predeterminados. Ejemplo 7.7 (Permutaciones de una palabra) Cuantas formas diferentes existen para permutar la palabra LALALAAA? para determinar una permutación necesitamos escoger como colocar las 5 letras A en ocho slots disponibles o en forma equivalente escoger donde pueden ir las 3 L’s Solución \\[\\binom{8}{5} =\\binom{8}{3} = \\frac{ 8.7.6}{3!} = 56\\text{ permutaciones}\\] Ejemplo 7.8 (Full house en poker) Una mano de 5 cartas es repartida desde una baraja estandar de 52 cartas, la mano es llamada un __full house_ si este consiste en tres cartas del mismo rango y dos cartas de otro rango, ejemplo tres 7’s y dos 10’s (en cualquier orden), cual es la probabilidad de un full house? Hay \\(\\binom{52}{5}=2598960\\) posibles manos , igualmente probables por simetría, asi que es aplicable la definición de probabilidad ingenua. Para encontrar el numero de manos de full house usamos la regla de multiplicación, Hay \\(13\\) rangos de cartas de una baraja por lo que hay \\(\\binom{13}{1}=13\\) de elegir un rango del trio y \\(\\binom{12}{1}\\) formas de elegir el rango del par necesario, este rango debe ser diferente al trio , Para el primer rango hay \\(\\binom{4}{3}\\) formas de seleccionar tres cartas de ese rango y \\(\\binom{4}{2}\\) formas de escoger las dos cartas del otro rango Por tanto tenemos un total de posibles formas de obtener fullhouse de \\[\\binom{13}{1} \\binom{4}{3} \\binom{12}{1} \\binom{4}{2} =3744\\] Por tanto si \\(F\\) es el evento de obtener un full house tenemos \\[P(F) = 3744/2598960 ≈ 0.0014405762304921968≈0.144\\% \\] Nota: Una baraja de poker estándar consta de 52 cartas divididas en cuatro palos: corazones (hearts), diamantes (diamonds), tréboles (clubs) y picas (spades). Cada palo contiene 13 cartas numeradas del 2 al 10, y luego tres cartas de figura: el Jack (J), la Reina (Q) y el Rey (K), junto con el As (A). Por lo tanto, las 52 cartas de una baraja de poker estándar son: Corazones (Hearts): A de corazones (A♥) 2 de corazones (2♥) 3 de corazones (3♥) 4 de corazones (4♥) 5 de corazones (5♥) 6 de corazones (6♥) 7 de corazones (7♥) 8 de corazones (8♥) 9 de corazones (9♥) 10 de corazones (10♥) J de corazones (J♥) Q de corazones (Q♥) K de corazones (K♥) Diamantes (Diamonds): A de diamantes (A♦) 2 de diamantes (2♦) 3 de diamantes (3♦) 4 de diamantes (4♦) 5 de diamantes (5♦) 6 de diamantes (6♦) 7 de diamantes (7♦) 8 de diamantes (8♦) 9 de diamantes (9♦) 10 de diamantes (10♦) J de diamantes (J♦) Q de diamantes (Q♦) K de diamantes (K♦) Tréboles (Clubs): A de tréboles (A♣) 2 de tréboles (2♣) 3 de tréboles (3♣) 4 de tréboles (4♣) 5 de tréboles (5♣) 6 de tréboles (6♣) 7 de tréboles (7♣) 8 de tréboles (8♣) 9 de tréboles (9♣) 10 de tréboles (10♣) J de tréboles (J♣) Q de tréboles (Q♣) K de tréboles (K♣) Picas (Spades): A de picas (A♠) 2 de picas (2♠) 3 de picas (3♠) 4 de picas (4♠) 5 de picas (5♠) 6 de picas (6♠) 7 de picas (7♠) 8 de picas (8♠) 9 de picas (9♠) 10 de picas (10♠) J de picas (J♠) Q de picas (Q♠) K de picas (K♠) Estas son las 52 cartas en una baraja de poker estándar. Ejemplo 7.9 (Escogiendo el complemento) Para cualquier \\(n,k\\) enteros positivos con \\(k \\leq n\\) \\[\\binom{n}{k}= \\binom{n}{n-k}\\] consideremos un comité de \\(n\\) personas de las cuales se escoge un equipo de \\(k\\) personas, ya sabemos que existen \\(\\binom{n}{k}\\) posibilidades , pero otra forma de conocer la cantidad posibilidades es buscar las \\(n-k\\) personas que no estan en el comité Ejemplo 7.10 (El capitán del equipo) Para cualquier \\(n,k\\) enteros positivos con \\(k \\leq n\\) \\[n\\binom{n-1}{k-1}= k\\binom{n}{k}\\] En forma sencilla consideremos un grupo de \\(n\\) personas de las cuales se escoge un equipo de \\(k\\) personas, uno de ellos podría ser el capitán del equipo. Inicialmente podemos escoger el capitán del equipo y el resto \\(k-1\\) como miembros del equipo. Equivalente a esto podríamos escoger primero los \\(k\\) miembros del equipo y luego escoger uno de ellos como el capitán Ejemplo 7.11 (Identidad de vandermonde's) Para cualquier \\(n,k\\) enteros positivos con \\(k \\leq n\\) \\[\\binom{m+n}{k}= \\sum_{j=0}^{k}\\binom{m}{j}\\binom{n}{k-j} \\] Consideremos un conjunto de \\(m\\) pavos reales y \\(n\\) tucanes, de los cuales se puede seleccionar un conjunto de \\(k\\) aves , hay entonces \\(\\binom{m+n}{k}\\) posibilidades para el conjunto de aves. Si hay \\(j\\) pavos reales en el conjunto entonces debe de haber \\(k-j\\) tucanes en el mismo conjunto. El lado derecho de la identidad suma todos los casos posibles. Ejemplo 7.12 (Dividir 12 personas en 3 equipos) Cuántas formas hay de dividir una docena de personas en 3 equipos, donde un equipo tiene 2 personas y los otros dos equipos tienen 5 personas cada uno? \\[\\frac{\\binom{12}{2}\\binom{10}{5}\\binom{5}{5}}{2}=8316\\] La división por 2 es porque por ejemplo, si las personas se nombran como [‘A’, ‘B’, ‘C’, ‘D’, ‘E’, ‘F’, ‘G’, ‘H’, ‘I’, ‘J’, ‘K’, ‘L’] el primer equipo puede estar conformado por A B el segundo equipo puede estar conformado por C, D, E, F, G el tercer equipo puede estar conformado por H, I, J, K, L Pero una posible combinación del segundo equipo puede ser también H, I, J, K, L y en el tercer equipo esta formado por C, D, E, F, G Ejemplo 7.13 (Dividir 12 personas en 3 equipos de 4 personas) Cuántas formas hay de dividir una docena de personas en 3 equipos, donde un equipo tiene 4 personas? \\[\\frac{\\binom{12}{4}\\binom{12}{4}\\binom{12}{4}}{3!}=5775\\] Ejemplo 7.13 (suma de combinatorias) Demostrar \\[\\binom{n}{k} + \\binom{n}{k-1} = \\binom{n+1}{k}\\] o lo que es lo mismo \\[ \\binom{n}{k} +\\binom{n}{k+1} = \\binom{n+1}{k+1}\\] Ejemplo 7.14 (telefono de 7 digitos) Cuántos números de teléfono de 7 dígitos son posibles, teniendo en cuenta que la primera cifra no puede iniciar con 0 o 1 \\(8*10*10*10*10*10*10=8000000\\) Ejemplo 7.15 (telefono de 7 digitos) Cuántos números de teléfono de 7 dígitos son posibles, pero esta vez no puede iniciar con 911 Existen \\(10^4\\) posibles valores que inician con \\(911\\) , basta con fijar el 911 y quedan \\(4\\) cifras usando la regla de multiplicación Por otro lado hay \\(8000000\\) de combinaciones que no inician ni con 0 ni con 1 Por tanto el numero de combinaciones posibles es \\[8000000-10000=7990000\\] Ejemplo 7.16 (partidas de ajedrez) Dos ajedrecistas, A y B, van a jugar 7 partidas. Cada juego tiene tres resultados posibles: una victoria para A (que es una derrota para B), un empate (empate) y una derrota para A (que es una victoria para B). Una victoria vale 1 punto, un empate vale 0.5 puntos y una derrota vale 0 puntos. ¿Cuántos resultados posibles hay para los juegos individuales, de modo que el jugador A en general termine con 3 victorias, 2 empates y 2 derrotas? Una forma de resolverlo es imaginando \\(7\\) posiciones y por tanto se pueden acomodar en esas 7 posiciones \\(\\binom{7}{2}\\) empates, en las otras 5 posiciones podemos acomodar \\(\\binom{5}{3}\\) victorias y en las ultimas 2 posiciones podemos acomodar \\(\\binom{2}{2}\\) para un total de posibilidades de \\[\\binom{7}{2} \\binom{5}{3} \\binom{2}{2}= 210\\] otra forma de resolverlo es con el coeficiente binomial (se puede usar cuando se necesita partir un grupo de \\(n\\) objetos en tres o mas grupos ) equivale a : 7 (7!) total de juegos en grupos de 3 (\\(3!\\)) y dos grupos de dos (2!) (2!) \\[\\frac{7!}{3!2!2!}=210\\] ¿Cuántos resultados posibles hay para los juegos individuales, de modo que A termine con 4 puntos y B termine con 3 puntos? tenemos estas posibilidades para que A termine con 4 puntos y B termine con tres puntos WDDDDDD WWDDDDL WWWDDLL WWWWLLL W es partido ganado, D partido empatado y L partido perdido \\[\\frac{7!}{1!6!} + \\frac{7!}{2!4!1!} + \\frac{7!}{3!2!2!} + \\frac{7!}{4!3!} = 357\\] Ejemplo 7.17 (ascensor) Tres personas se suben a un ascensor vacío en el primer piso de un edificio que tiene pisos. Cada uno presiona el botón del piso deseado (a menos que uno de los otros ya haya presionado ese botón). Suponga que es igualmente probable que quieran pasar por los pisos (independientemente el uno del otro). ¿Cuál es la probabilidad de que se presionen los botones de pisos consecutivos? Solucion: El numero total de posibles resultados descartando el 1 es \\(9^3\\) Hay 7 posibilidades por parte de las personas de subir a pisos consecutivos (2,3,4), (3,4,5), (4,5,6), (5,6,7), (6,7,8), (7,8,9), (8,9,10) y por cada una de esas posibilidades, las personas pueden escoger \\(3!\\) maneras, La definición de probabilidad ingenua entonces nos dice que la probabilidad es: \\[\\frac{7*3!}{9^3}=0.057613169\\] Ejemplo 7.18 (cujple años en) La probabilidad de que tres personas en un grupo de tres nazcan en enero 1 es mayor , menor o igual que la probabilidad de que en un gruṕo de tres personas una nace en enero 1, otra nace en enero 2 y otra nace en enero 3 Solucion: El numero total de posibles resultados es \\(365^3\\) Hay una sola posibilidad en que tres personas nazcan el día 1 de enero , por tanto la probabilidad de que nazcan el día 1 de enero es : \\[\\frac{1}{365^3} \\] Hay \\(3!\\) posibilidades de que una persona del grupo nazca el día 1 , otra el dia 2 y otra el dia 3 por tanto la probabilidad es \\[\\frac{6}{365^3} \\] Por tanto La probabilidad de que tres personas en un grupo de tres nazcan en enero 1 es menor que la probabilidad de que en un grupo de tres personas una nace en enero 1, otra nace en enero 2 y otra nace en enero 3 References "],["probabilidad.html", "Capítulo 8 Probabilidad 8.1 Definición general de Probabilidad", " Capítulo 8 Probabilidad 8.1 Definición general de Probabilidad Hasta ahora se ha revisado varios métodos para contar los resultados en un espacio muestral, lo que permite calcular probabilidades aplicando la definición ingenua. Pero la definición ingenua solo puede llevarnos hasta cierto punto, ya que se requieren resultados igualmente probables y no puede manejar un espacio muestral infinito. Ahora se muestra la definición general de probabilidad Definición 8.1 (Definición general de probabilidad) Un espacio de probabilidad consiste en un espacio muestral \\(S\\) y una función de probabilidad \\(P\\) el cual toma un evento \\(A \\subseteq S\\) como entrada y retorna \\(P(A)\\), un número real entre \\(0\\) y \\(1\\), como salida, la función \\(P\\) debe satisfacer los siguientes axiomas: Probabilidad de evento nulo y espacio muestral \\[\\begin{equation} P(\\emptyset)=0,P(S)=1 \\tag{8.1} \\end{equation}\\] Si \\(A_1, A_2, A_3, ...\\) son eventos disjuntos , entonces \\[\\begin{equation} P\\left(\\bigcup_{j=1}^{\\infty} A_j\\right)=\\sum_{j=0}^{k} P(A_j) \\tag{8.2} \\end{equation}\\] Decimos que esos eventos son disjuntos significa que ellos son mutuamente excluyentes: \\(A_i \\cap A_j = \\emptyset, \\quad \\text{para } i \\neq j\\) En el mundo de las canicas, la definición dice que la probabilidad se comporta como la masa: La masa de una pila vacía de canicas es \\(0\\), la masa total de todas las canicas es \\(1\\) , y si tenemos pilas de canicas que no se superponen, podemos obtener su masa combinada sumando las masas de las pilas individuales. A diferencia del caso ingenuo, ahora podemos tener canicas de diferentes masas y también podemos tener un numero infinito numerable de canicas siempre que su masa total es \\(1\\) Cualquier función \\(P (\\text{mapeo de eventos a numeros en el intervalo [0,1])}\\) que satisface los dos axiomas es considerada un funcion valida de probabilidad, sin embargo, los axiomas no dicen como debe ser interpretada la probabilidad La visión frecuentista de probabilidad es que representa una frecuencia a largo plazo durante un gran número de repeticiones de un experimento: si decimos que una moneda tiene probabilidad de \\(1/2\\) de obtener una cara, significaría que la moneda arrojaría caras el 50% de las veces si las tiráramos una y otra vez. La visión Bayesiana de probabilidad representa un grado de creencia sobre el evento en cuestión, por lo que podemos asignar probabilidades a hipótesis como “el candidato A podría ganar la elección” o “el acusado es culpable”, incluso si no es posible repetir la misma elección o el mismo crimen una y otra vez. Las perspectivas Bayesiana y frecuentista con complementarias y ambas se ayudan, Independientemente de como elijamos interpretar la probabilidad, podemos usar los dos axiomas para derivar otras propiedades de la probabilidad, y estos resultados se mantendrán para cualquier función de probabilidad válida. Teorema 8.1 (Propiedades de la probabilidad) La probabilidad tiene los siguientes propiedades para cualquier evento A y B \\[\\begin{equation} P(A^c)=1 - P(A) \\tag{8.3} \\end{equation}\\] Si \\(A \\subseteq B\\), entonces \\[\\begin{equation} P(A) \\leq P(B) \\tag{8.4} \\end{equation}\\] \\[\\begin{equation} \\text{P}(A \\cup B) = \\text{P}(A) + \\text{P}(B) - \\text{P}(A \\cap B) \\tag{8.5} \\end{equation}\\] Demostración 1 Puesto que \\(A\\) y \\(A^c\\) son disjuntos, \\(S = A \\cup A^c\\) y por el segundo axioma tenemos \\[P(S) = P (A) + P(A^c) \\] Pero como \\(P(S)=1\\) \\[P (A) + P(A^c) = 1\\] Demostración 2 Si \\(A \\subseteq B\\), tenemos que \\[B = ( A \\cap B) \\cup (B-A)= A \\cup (B-A)\\] El axioma 2 nos dice que \\(P(B) = P(A)+ P(B-A)\\) Así \\(P(B-A) \\geq 0 =&gt; P(A) \\leq P(B)\\) Figura 8.1: cuando A es subconjunto de B Demostración 3 \\[A \\cup B = (A-B) \\cup (B-A) \\cup (A \\cap B)\\] Figura 8.2: cuando A es subconjunto de B Por tanto \\[P(A \\cup B)= P(A-B)+P(B-A) +P(A \\cap B)\\] Puesto que \\[A = ( A \\cap B ) \\cup (A-B),B = ( A \\cap B ) \\cup (B-A)\\] obtenemos \\[P(A) = P(A \\cap B) + P(A-B), P(B) = P(A \\cap B) + P(B-A) \\] Y con un par de reemplazos obtenemos (8.5) Teorema 8.2 (Principio de inclusión - exclusión) Sea \\(A_1, A_2, ..., A_n \\in S\\) entonces \\[\\begin{equation} P\\left(\\bigcup_{k=1}^{n}A_k\\right)=\\sum_{k=1}^{n} P(A_k) - \\sum_{k_1&lt;k_2}^{n}\\text{P}(A_{k_1} \\cap A_{k_2}) + \\\\ \\sum_{k_1&lt;k_2&lt;k_3}^{n}\\text{P}(A_{k_1} \\cap A_{k_2} \\cap A_{k_3})+...+ \\\\ (-1)^{n+1}P\\left(\\bigcap_{k=1}^{n}A_k \\right) \\tag{8.6} \\end{equation}\\] Ejemplo 8.1 (el problema de las cartas de Montmort's) Consideremos una baraja de \\(n\\) cartas bien barajada, etiquetadas de \\(1\\) hasta \\(n\\), volteamos la carta una por una, diciendo los num eros desde \\(1\\) hasta \\(n\\), se gana el juego si en algún momomento, el numero que se dioce en voz alta es el mismo que el número de la carta que se esta volteando ( por ejemplo, si la 7ma carta del mazo tiene la etiqueta 7), ¿cuál es la probabilidad de ganar? Solucion Sea \\(A_i\\) el evento en que la carta \\(i\\)esima en la baraja tiene el numero \\(i\\) escrito, estamos entonces interesados en la probabilidad de la union \\(A_1 \\cup A_2 \\cup ... \\cup A_n\\) , se gana el juego si al menos una de las cartas tiene el número que coincida con su posición en el mazo. (Un pedido por el que pierdes de llama trastorno mental, aunque es de esperar que nadie se haya trastornado nunca debido a perder en este juego) \\[P(A_i)=\\frac{1}{n}\\] para \\(i &lt;= n\\) puesto que hay \\(n\\) cartas y la probabilidad de obtener la carta \\(i\\) es \\(\\frac{1}{n}\\) Otra forma de ver esto es usando el espacio muestral completo es decir hay \\(n!\\) posibles formas de ordenar la baraja, todas igualmente probables , y \\((n-1)!\\) de esas son favorables a \\(A_i\\) (se fija la carta numerada \\(i\\) en la posición \\(i\\) es una en la baraja y entonces todas las restantes cartas pueden estar en cualquier orden) \\[P(A_i \\cap A_j) = \\frac{(n-2)!}{n!}= \\frac{1}{n(n-1)}\\] Puesto que se requiere que las cartas numeradas \\(i\\) y \\(j\\) estén la \\(i\\) y \\(j\\) posición en la baraja y por tanto las \\(n-2\\) cartas puedan estar en cualquier orden, por tanto \\((n-2)!\\) de las \\(n!\\) son favorables a \\(P(A_i \\cap A_j)\\) Similarmente \\[P(A_i \\cap A_j \\cap A_k ) = \\frac{(n-3)!}{n!}= \\frac{1}{n(n-1)(n-2)}\\] Y el patrón continua por intersecciones de 4 eventos En la fórmula de inclusión-exclusión, hay \\(n\\) términos involucrando un evento , \\(\\binom{n}{2}\\) términos involucrando dos eventos , \\(\\binom{n}{3}\\) términos involucrando tres eventos , y así sucesivamente. \\[P\\left(\\bigcup_{i=1}^{n}A_i\\right)=\\frac{n}{n}-\\frac{\\binom{n}{2}}{n(n-1)} + \\frac{\\binom{n}{3}}{n(n-1)(n-2)}-...+(-1)^{n+1}\\frac{1}{n!} \\\\ =1-\\frac{1}{2!}+\\frac{1}{3!}-...+(-1)^{n+1}\\frac{1}{n!} \\] La serie de Taylor nos dice: \\[e^{-1}=1-\\frac{1}{1!}+\\frac{1}{2!}-\\frac{1}{3!}+...,\\] de lo cual \\[1-e^{-1}=\\frac{1}{1!}-\\frac{1}{2!}+\\frac{1}{3!}+...,\\] reemplazando \\[P\\left(\\bigcup_{i=1}^{n}A_i\\right)=1 - \\frac{1}{e}\\] Así que para grandes \\(n\\) la probabilidad de ganar el juego es extremadamente cercana a \\(1-\\frac{1}{e} ≈ 0.63\\) A die is a cube whose 6 sides are labeled with the integers from 1 to 6. The die is fair if all 6 sides are equally likely to come up on top when the die is rolled. The plural form of “die” is “dice”. Ejemplo 7.13 (suma de combinatorias) Sabemos que un dado es un cubo de 6 caras etiquetadas del 1 al 6. El dado es justo si todas las caras tienen igual probabilidad de salir cuando el dado es tirado Cual es la probabilidad es maayor, que después de lanzar 4 dados la suma de sus caras es 21 o la probabilidad de que después de lanzar 4 dados la suma de las caras es 22 Para obtener 21 solo tenemos las siguientes posibilidades \\((6,6,6,3)\\) 4 posibilidades \\((5,5,5,6)\\) 4 posibilidades \\((6,6,5,4)\\) 12 posibilidades después de permutar Para un total de 20 posibilidades Y para obtener 22 debemos permutar \\((6,6,5,5)\\) 6 posibilidades \\((6,6,6,4)\\) 4 posibilidades Para un total de 10 posibilidades Por tanto la probabilidad de obtener 21 es mas grande que la posibilidad de obtener 22 Ejemplo 8.2 (captura-recaptura) Los alces habitan en un cierto bosque, hay \\(N\\) alces de los cuales se captura una muestra aleatoria de tamaño \\(n\\) , los alces capturados se retornan a la población y se toma una nueva muestra , esta vez de tamaño \\(m\\), este método es conocido en ecología como captura-recaptura. Cual es la probabilidad de que exactamente \\(k\\) de los \\(m\\) alces en la nueva muestra sea tomada otra vez. \\[P(X = k) = \\frac{\\binom{n}{k}\\binom{N-n}{m-k} }{\\binom{N}{m}}\\] Donde:\\ \\(\\binom{n}{k}\\) es el número de formas de elegir \\(k\\) alces de la primera muestra de tamaño \\(m\\)\\ \\(\\binom{N-n}{m-k}\\) es el número de formas de elegir \\(m-k\\) alces que no fueron capturados en la primera muestra de los \\(N-n\\) alces restantes de la población\\ \\(\\binom{N}{m}\\) es el número de formas de elegir \\(m\\) alces de la población total de \\(N\\) alces\\ Esto se conoce como la probabilidad hypergeométrica "],["probabilidad-condicional.html", "Capítulo 9 Probabilidad condicional 9.1 Definición de Probabilidad condicional 9.2 Regla de bayes y probabilidad total", " Capítulo 9 Probabilidad condicional El condicionamiento es una estrategia de resolución de problemas muy poderosa, que a menudo permite resolver un problema complicado descomponiéndolo en partes manejables con un razonamiento caso por caso. Debido a la importancia central del condicionamiento, decimos que el condicionamiento es el alma de las estadístic 9.1 Definición de Probabilidad condicional Definición 9.1 (Definicion de probabilidad condicional) si \\(A\\) y \\(B\\) son eventos con \\(P(B)&gt;0\\) entonces la probabilidad condicional de \\(A\\) dado \\(B\\) denotado por \\(P(A|B)\\) se define como : \\[\\begin{equation} P(A|B)=\\frac{ P(A \\cap B)}{P(B)} \\tag{9.1} \\end{equation}\\] Aquí \\(A\\) es el evento cuya incertidumbre queremos actualizar y \\(B\\) es la evidencia que observamos (o queremos tratar como dada). LLamamos \\(P(A)\\) la probabilidad a priori de \\(A\\) y $P(A|B) la probabilidad a posteriori de A ( a priori antes de actualizar basada en el evidencia y a posteriori significa después de actualizar basada en la evidencia). Definición 9.2 (Dos cartas) Una baraja estándar de 52 cartas se baraja bien, se extraen dos cartas aleatoriamente, una a la vez sin reemplazo. Sea \\(A\\) el evento en que la primera carta es un corazón, y \\(B\\) el evento en que la segunda carta es roja. Encontrar \\(P(A|B)\\) y \\(P(B|A)\\) solucion \\[P(A \\cap B)=\\frac{13.25}{52.51}=\\frac{25}{204}\\] \\[P(A)=13/52=1/4\\] \\[P(B)=(26/52).(51/51)=1/2\\] por tanto \\[P(A|B)= \\frac{ P( A \\cap B)}{P(B)}=\\frac{25/204}{1/2}=25/102\\] \\[P(B|A)= \\frac{ P( A \\cap B)}{P(A)}=\\frac{25/204}{1/4}=25/51\\] 9.2 Regla de bayes y probabilidad total Teorema 9.1 (Probabilidad de la intersección de dos eventos) para cualquier par de eventos \\(A\\) y \\(B\\) con probabilidades positivas \\[\\begin{equation} P( A \\cap B) =P(B)P(A|B) = P(A)P(B|A) \\tag{9.2} \\end{equation}\\] Teorema 9.2 (Probabilidad de la intersección de n eventos) Para cualquier eventos \\(A_1,...,A_n\\) con probabilidades positivas \\[\\begin{equation} P( A_1, A_2, A_3,...,A_n) =P(A_1)P(A_2|A_1)P(A_3|A_1,A_2)...P(A_n|A_1,...,A_{n-1}) \\tag{9.3} \\end{equation}\\] Las comas representan int ersecciones. Por ejemplo \\(P(A_3|A_1,A_2)\\) es la probabilidad de que ocurra \\(A_3\\) dado que ambos \\(A_1\\) y \\(A_2\\) ocurran. Teorema 9.3 (Regla de Bayes) para cualquier par de eventos \\(A\\) y \\(B\\) con probabilidades positivas \\[\\begin{equation} P( A|B) =\\frac{P(B|A)P(A)}{P(B)} \\tag{9.4} \\end{equation}\\] Teorema 9.4 (Ley de la probabilidad total) sea \\(A_1,...,A_n\\) partición del espacio muestral \\(S\\) , los \\(A_i\\) son eventos disjuntos y \\(\\bigcup_{i=1}^{n}A_i=S\\) \\[\\begin{equation} P( B) =\\sum_{i=1}^{n}P(B|A_i)P(A_i) \\tag{9.5} \\end{equation}\\] Demostracion Puesto que \\(A_i\\) forman particiones de \\(S\\), podemos descomponer \\(B\\) como \\[B=(B \\cap A_1) \\cup (B \\cap A_2) \\cup ...\\cup (B \\cap A_n) \\] Por tanto \\[P(B)=P(B \\cap A_1) + ... + P (B \\cap A_n)=P(B/A_1)P(A_1)+...+P(B/A_n)P(A_n)\\] Figura 9.1: Particion \\(A_i\\) Ejemplo 9.1 (moneda aleatoria) Tenemos una moneda justa y otra moneda sesgada en la cual sale cara con probabilidad de \\(3/4\\) , se elige una moneda al azar y se tira tres veces. Si se obtiene cara las tres veces , cual es la probabilidad de que la moneda elegida sea la justa? Solución Sea \\(A\\) el evento en que la moneda escogida se obtiene cara tres veces y sea \\(F\\) el evento en que elegimos la moneda justa, por tanto estamos interesados en la \\(P(F|A)\\), es más fácil encontrar P(A|F) \\[\\begin{align*} P(F|A) &amp;= \\frac{P(A|F) P(F)}{P(A)} \\\\ &amp;= \\frac{P(A|F) P(F)}{P(A|F) P(F) + P(A|F^c) P(F^c)} \\\\ &amp;= \\frac{(1/2)^3 \\cdot 1/2}{(1/2)^3 \\cdot 1/2 + (3/4)^3 \\cdot 1/2} \\\\ &amp;\\approx 0.23. \\end{align*}\\] Ejemplo 9.1 (moneda aleatoria) Jimmy esta siendo pruebas diagnosticas para saber si tiene la enfermedad llamada condicionitis, una condición médica que aflige al \\(1\\%\\) de la población, su resultado es positivo, es decir , el test afirma que Jimmy tiene la enfermedad. Sea \\(D\\) el evento en que Jimmy tiene la enfermedad , sea \\(T\\) el evento que el es positivo. Supongamos que los test tienen una precisión del \\(95\\%\\) es decir asumimos en esta problema que \\(P(T|D)=0.95\\) y \\(P(T^c|D^c)=0.95\\) la cantidad de \\(P(T|D)\\) se conoce como la sensitividad o tasa de verdadero positivo de la prueba y \\(P(T^c|D^c)\\) es conocida como la especificidad o _$$tasa de verdaderos negativos de la prueba. Encontrar la probabilidad de que Jimmy tiene condicionitis dado el resultado provisto por la prueba. Solución Queremos hallar \\(P(D|T)\\) \\[\\begin{align*} P(D|T) &amp;= \\frac{P(T|D)P(D)}{P(T)} \\\\ &amp;= \\frac{P(T|D)P(D)}{P(T|D)P(D) + P(T|D^c)P(D^c) } \\\\ &amp;= \\frac{0.95 . 0.01}{ 0.95.0.01 + 0.05*0.99 } \\\\ &amp;\\approx 0.16 \\end{align*}\\] Por tanto hay 16% de que Jimmy tenga la enfermedad, dado que el resultado es positivo, aunque la prueba parece ser confiable. A muchas personas les sorprende que la probabilidad condicional de tener la enfermedad con un resultado positivo en la prueba sea de solo el 16%, a pesar de que la prueba tiene una precisión del 95%. La clave para comprender esta probabilidad posterior sorprendentemente alta es darse cuenta de que hay dos factores en juego: la evidencia de la prueba y nuestra información previa sobre la prevalencia de la enfermedad. La probabilidad condicional refleja un equilibrio entre estos dos factores, sopesando adecuadamente la rareza de la enfermedad frente a la rareza de los resultados erróneos de una prueba. "],["sourcecode.html", "A Codigo fuente Python A.1 Codigo python para dibujar probabilidad A.2 regresion lineal", " A Codigo fuente Python A.1 Codigo python para dibujar probabilidad Código fuente realizado en python para dibujar la probabilidad en función de \\(k\\) de que al menos dos fechas de nacimiento de un conjunto de personas coinciden, \\(k\\) es el numero de personas import matplotlib.pyplot as plt def calcular_probabilidad(k): numerador = 1 for i in range(365 - k + 1, 366): numerador *= i denominador = 365 ** k return 1 - numerador / denominador k_values = list(range(1, 101)) # Valores de k de 1 a 100 probabilidades = [calcular_probabilidad(k) for k in k_values] plt.plot(k_values, probabilidades, marker=&#39;.&#39;, linestyle=&#39;&#39;) plt.xlabel(&#39;Número de personas (k)&#39;) plt.ylabel(&#39;Probabilidad de al menos una coincidencia&#39;) plt.title(&#39;Probabilidad de coincidencia de cumpleaños vs Número de personas&#39;) plt.grid(True) # Línea en el 50% plt.axhline(y=0.5, color=&#39;r&#39;, linestyle=&#39;-&#39;) #plt.show() plt.savefig(&#39;grafico_probabilidad_cumpleanos.png&#39;) A.2 regresion lineal plot(cars) # a scatterplot Figura A.1: (ref:foo) "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
